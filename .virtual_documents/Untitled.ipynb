import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns 
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder


credit = pd.read_csv("german_credit_data.csv")
credit


credit.info()


credit.describe()


credit.isnull().sum()


credit = credit.drop("Unnamed: 0", axis=1)
credit


credit["Saving accounts"].value_counts()


credit["Checking account"].value_counts()


credit[["Saving accounts", "Checking account"]]





accounts = credit[["Saving accounts", "Checking account"]]


accounts = accounts.dropna(axis=0)
accounts.shape


accounts.isnull().sum()


print("Distribution de: ", accounts["Saving accounts"].value_counts())
print("---"*20)
print("Distribution de:", accounts["Checking account"].value_counts())


saving_counts = accounts["Saving accounts"].value_counts().reset_index()
saving_counts.columns = ["Saving accounts", "Count"]

sns.barplot(data=saving_counts, x="Saving accounts", y="Count", palette="viridis")
plt.title("Fréquence des différentes modalités de Saving accounts")
plt.xlabel("Modalités de Saving accounts")
plt.ylabel("Nombre d'occurrences")


checking_account = accounts["Checking account"].value_counts().reset_index()
checking_account.columns = ["Checking account", "Count"]

sns.barplot(data=checking_account, x="Checking account", y="Count", palette="viridis")
plt.title("Fréquence des différentes modalités de Checking account")
plt.xlabel("Modalités de Checking account")
plt.ylabel("Nombre d'occurrences")


saving_checking = accounts.groupby(["Checking account", "Saving accounts"]).value_counts().reset_index()
saving_checking


sns.barplot(data=saving_checking, x="Saving accounts", y="count", hue="Checking account", palette="viridis")
plt.title("Fréquence des Saving accounts par Checking account")
plt.xlabel("Saving accounts")
plt.ylabel("Nombre d'occurrences")
plt.legend(title="Checking account")


sns.barplot(data=saving_checking, x="Checking account", y="count", hue="Saving accounts", palette="viridis")
plt.title("Fréquence des Checking account par Saving accounts")
plt.xlabel("Checking account")
plt.ylabel("Nombre d'occurrences")
plt.legend(title="Saving accounts")





credit[credit.isnull().any(axis=1)]


credit.loc[credit.isnull().any(axis=1), ["Saving accounts", "Checking account"]]


le_saving = LabelEncoder()
le_checking = LabelEncoder()

replacer1 = {
        'little': 0,
        'moderate':1,
        'quite rich':2,
        'rich':3
    }

replacer2 = {
    "bad":0,
    "good":1
}

credit_encoded = pd.get_dummies(credit, columns=["Sex", "Housing", "Purpose"])
credit_encoded["Saving accounts"] = credit_encoded["Saving accounts"].replace(replacer1).fillna(-1).astype(int)
credit_encoded["Checking account"] = credit_encoded["Checking account"].replace(replacer1).fillna(-1).astype(int)
credit_encoded["Saving accounts"] = credit_encoded["Saving accounts"].replace(
    {-1: np.nan}
)
credit_encoded["Checking account"] = credit_encoded["Checking account"].replace(
    {-1: np.nan}
)
credit_encoded["Risk"] = credit_encoded["Risk"].replace(replacer2)
credit_encoded


sns.boxplot(credit)


colonnes = ["Age", "Job", "Credit amount", "Duration"]

for colonne in colonnes:
    sns.boxplot(credit_encoded, x=colonne)
    plt.show()


sns.boxplot(credit_encoded, x ="Saving accounts", y="Credit amount")
plt.show()
sns.boxplot(credit_encoded, x ="Checking account", y="Credit amount")
plt.show()


imputer = KNNImputer(n_neighbors=5)
credit_imputed = imputer.fit_transform(credit_encoded)
credit_imputed = pd.DataFrame(imputer.fit_transform(credit_encoded), columns=credit_encoded.columns)
data = credit_imputed.round().astype(int)
data


data["Checking account"].value_counts()


from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split


X = data.drop(["Risk"], axis=1)
y = data["Risk"]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


knn = KNeighborsClassifier(n_neighbors=5)


knn.fit(X_train, y_train)


knn.score(X_train, y_train)


knn.score(X_test, y_test)


neighbors = range(1, 11)
test_costs = []
train_costs = []


for i in neighbors:
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    train_costs.append(knn.score(X_train, y_train))
    test_costs.append(knn.score(X_test, y_test))


plt.plot(neighbors, train_costs, label='Training Cost', linestyle='-', marker='o')
plt.plot(neighbors, test_costs, label='Testing Cost', linestyle='--', marker='s')


knn = KNeighborsClassifier(n_neighbors=9)


knn.fit(X_train, y_train)


knn.score(X_train, y_train)


knn.score(X_test, y_test)


from sklearn.ensemble import RandomForestClassifier

# Modèle Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)


rf_model.score(X_train, y_train)


rf_model.score(X_test, y_test)


from sklearn.model_selection import GridSearchCV

# Définir les hyperparamètres à tester
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 5, 10],
    'max_features': ['sqrt', 'log2']
}

# Initialiser GridSearchCV
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    scoring='accuracy',
    cv=5,  # Validation croisée à 5 folds
    n_jobs=-1,  # Utilise tous les cœurs disponibles
    verbose=2
)

# Lancer la recherche
grid_search.fit(X_train, y_train)

# Meilleurs paramètres
print("Meilleurs paramètres : ", grid_search.best_params_)
print("Score avec les meilleurs paramètres : ", grid_search.best_score_)



grid_search.best_estimator_.score(X_test, y_test)





knn = KNeighborsClassifier(n_neighbors=9)
knn.fit(X_train, y_train)


import pickle


with open("credit_score.pkl", "wb") as file:
    pickle.dump(knn, file)



